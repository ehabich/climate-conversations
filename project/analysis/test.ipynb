{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def compute_unigram_frequency(comment, moral_foundations_words):\n",
    "    # Assuming `comment` is already tokenized and `moral_foundations_words` is a list of relevant words.\n",
    "    unigram_counts = {}\n",
    "    total_words = len(comment)\n",
    "\n",
    "    # Initialize counts for each foundation to 0\n",
    "    for foundation in moral_foundations_words:\n",
    "        unigram_counts[foundation] = 0\n",
    "\n",
    "    # Count the occurrences of each foundation word in the comment\n",
    "    for word in comment:\n",
    "        if word in moral_foundations_words:\n",
    "            unigram_counts[word] += 1\n",
    "\n",
    "    # Handle the case where `total_words` is zero to prevent division by zero\n",
    "    if total_words > 0:\n",
    "        # Convert counts to frequencies\n",
    "        unigram_frequencies = {word: count / total_words for word, count in unigram_counts.items()}\n",
    "    else:\n",
    "        # If there are no words, return a dictionary with zero frequencies\n",
    "        unigram_frequencies = {word: 0 for word in moral_foundations_words}\n",
    "\n",
    "    return unigram_frequencies\n",
    "\n",
    "\n",
    "def classify_sentence_with_profile(sentence, moral_foundations_dict):\n",
    "    foundation_scores = {}\n",
    "    \n",
    "    # Loop through each moral foundation and its associated words\n",
    "    for foundation, words in moral_foundations_dict.items():\n",
    "        # Compute the sum of frequencies of foundation words in the sentence\n",
    "        frequencies = compute_unigram_frequency(sentence, words)\n",
    "        foundation_score = sum(frequencies.values())  # Sum of all word frequencies for this foundation\n",
    "        foundation_scores[foundation] = foundation_score\n",
    "\n",
    "    return foundation_scores\n",
    "\n",
    "\n",
    "\n",
    "with open(\"lemmatized_moral_foundations_dictionary.json\", \"r\") as f:\n",
    "        word_to_moral_foundation_expanded = json.load(f)\n",
    "\n",
    "classification_profiles = []\n",
    "\n",
    "for comment in full_df[\"tokenized_body_words_norm\"]:\n",
    "    classification_profile = classify_sentence_with_profile(\n",
    "        comment, word_to_moral_foundation_expanded\n",
    "    )\n",
    "    classification_profiles.append(classification_profile)\n",
    "\n",
    "# Convert classification_profiles to a DataFrame\n",
    "classification_df = pd.DataFrame(classification_profiles)\n",
    "\n",
    "# Concatenate this DataFrame with full_df\n",
    "full_df = pd.concat([full_df.reset_index(drop=True), classification_df.reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moralstrength import string_moral_values\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "full_df = full_df[full_df['subreddit'] == 'climate']\n",
    "\n",
    "# Assuming full_df is already defined and filtered for 'climate' subreddit\n",
    "# Ensure your DataFrame is correctly loaded and filtered before this point\n",
    "\n",
    "def process_text_and_return_dict(text, model='unigram+freq'):\n",
    "    result = string_moral_values(text, model=model)\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row in 'body' column and create a DataFrame from the resulting series of dictionaries\n",
    "morals_expanded = full_df['body'].apply(lambda text: process_text_and_return_dict(text, 'unigram+freq'))\n",
    "morals_df = pd.DataFrame(morals_expanded.tolist())\n",
    "\n",
    "# Concatenate the new DataFrame with the original DataFrame\n",
    "full_df = pd.concat([full_df.reset_index(drop=True), morals_df.reset_index(drop=True)], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
