{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is used to run the tokenizer and and moral classifier in parallel on Google CoLab's High Ram CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX3h9mElehhq",
        "outputId": "a034802b-19e1-43ad-c995-4e26259eabbf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40jiv-DKgvUU",
        "outputId": "4519d492-4daf-438c-8d74-c099bfb9a2f7"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/climate-conversations-kathryn/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxauRs32ejKz",
        "outputId": "42be1eec-a0de-47b1-ec23-ba739aeaa41f"
      },
      "outputs": [],
      "source": [
        "!apt-get install python3.11\n",
        "!ln -sf /usr/bin/python3.11 /usr/local/bin/python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWZFlk3yeq1K"
      },
      "outputs": [],
      "source": [
        "# !pip install poetry\n",
        "# !poetry config virtualenvs.in-project true\n",
        "# !poetry install --no-ansi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZCOs9E9lOvv"
      },
      "outputs": [],
      "source": [
        "!source .venv/bin/activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_2dr_kkesdz",
        "outputId": "aa5efaa9-dedb-49cd-f874-684bdd3420e8"
      },
      "outputs": [],
      "source": [
        "%cd project/analysis/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ks2J1zHm0lF",
        "outputId": "c539e288-0343-4c89-97d4-34d9e13c4cc3"
      },
      "outputs": [],
      "source": [
        "!pip install moralstrength"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZQbgcJfjDU5"
      },
      "outputs": [],
      "source": [
        "# !python3 moral_strength_classifier.py --subreddit worldnews --utc_start 1662654781 --utc_end 1662703120 --rows 0,1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dYpWbZ7E0taF",
        "outputId": "e23926c8-c65c-4d84-81d0-52b6e1724a54"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "import subprocess\n",
        "\n",
        "def run_subreddit(subreddit):\n",
        "    \"\"\"Function to run a shell command.\"\"\"\n",
        "    command = \"python3 moral_strength_classifier.py --subreddit {}  \"\n",
        "    formatted_command = command.format(subreddit)\n",
        "    print(f\"Running command '{formatted_command}'\")\n",
        "    try:\n",
        "        output = subprocess.check_output(formatted_command, stderr=subprocess.STDOUT, shell=True, universal_newlines=True)\n",
        "        print(f\"Command '{command}' output:\\n{output}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error executing '{command}':\\n{e.output}\")\n",
        "\n",
        "def main():\n",
        "    subreddits = [\n",
        "      'worldnews',\n",
        "      'climateskeptics',\n",
        "      'climate',\n",
        "      'environment',\n",
        "      'climatechange',\n",
        "      'climateoffensive',\n",
        "      'science',\n",
        "      'politics',\n",
        "    ]\n",
        "\n",
        "    pool = multiprocessing.Pool(processes=len(subreddits))\n",
        "\n",
        "    pool.map(run_subreddit, subreddits)\n",
        "\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
