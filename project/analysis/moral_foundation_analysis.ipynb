{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "parent_directory = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "sys.path.append(parent_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Read in the Reddit Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parent_directory = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "\n",
        "directory = os.path.join(parent_directory,'data_collection/project_data/')\n",
        "\n",
        "full_df = pd.DataFrame()\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".pkl\"):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        df = pd.read_pickle(file_path)\n",
        "\n",
        "        print(f\"Data from {filename}:\")\n",
        "        #print(df.head())\n",
        "\n",
        "        full_df = pd.concat([full_df, df], ignore_index=True)\n",
        "\n",
        "print(\"Combined DataFrame:\")\n",
        "print(full_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df = full_df[0:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "if os.path.exists(\"wordvectors.kv\"):\n",
        "    word_vectors = KeyedVectors.load(\"wordvectors.kv\")\n",
        "else:\n",
        "    import gensim.downloader as api\n",
        "\n",
        "    word_vectors = api.load(\"glove-twitter-200\")\n",
        "    word_vectors.save(\"wordvectors.kv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_similarity(comment, foundation_words_vec, similarity_threshold=0.25):\n",
        "    similarities = []\n",
        "    for word in comment:  # word in reddit comment\n",
        "        try:\n",
        "            word_vec = word_vectors[word]  # get the embedding\n",
        "            for foundation_word_vec in foundation_words_vec:  # loop through moral foundation words\n",
        "                sim = np.dot(word_vec, foundation_word_vec) / (np.linalg.norm(word_vec) * np.linalg.norm(foundation_word_vec))\n",
        "                # Apply threshold\n",
        "                if sim >= similarity_threshold:\n",
        "                    similarities.append(sim)\n",
        "        except KeyError:  # If the word is not in the embedding vocabulary\n",
        "            pass\n",
        "    \n",
        "    if similarities:\n",
        "        return np.mean(similarities)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def classify_sentence_with_profile(sentence, moral_foundations_dict):\n",
        "    foundation_scores = {}\n",
        "\n",
        "    for foundation, words in moral_foundations_dict.items():\n",
        "        words_vec = []\n",
        "        for word in words:\n",
        "            try:  # loop through moral foundation words\n",
        "                word_vec = word_vectors[word]\n",
        "                words_vec.append(word_vec)\n",
        "            except:\n",
        "                pass\n",
        "        foundation_scores[foundation] = compute_similarity(sentence, words_vec)\n",
        "\n",
        "    return foundation_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"expanded_moral_foundations_dictionary.json\", \"r\") as f:\n",
        "        word_to_moral_foundation_expanded = json.load(f)\n",
        "\n",
        "classification_profiles = []\n",
        "\n",
        "for comment in full_df[\"tokenized_body_words_norm\"]:\n",
        "    classification_profile = classify_sentence_with_profile(\n",
        "        comment, word_to_moral_foundation_expanded\n",
        "    )\n",
        "    classification_profiles.append(classification_profile)\n",
        "\n",
        "# Convert classification_profiles to a DataFrame\n",
        "classification_df = pd.DataFrame(classification_profiles)\n",
        "\n",
        "# Concatenate this DataFrame with full_df\n",
        "full_df = pd.concat([full_df.reset_index(drop=True), classification_df.reset_index(drop=True)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df['Harm_Care_Agg'] = (full_df['HarmVice'] + full_df['HarmVirtue']) / 2\n",
        "full_df['Authority_Agg'] = (full_df['AuthorityVice'] + full_df['HarmVirtue']) / 2\n",
        "full_df['Purity_Agg'] = (full_df['PurityVice'] + full_df['PurityVirtue']) / 2\n",
        "full_df['Fairness_Agg'] = (full_df['FairnessVice'] + full_df['FairnessVirtue']) / 2\n",
        "full_df['Ingroup_Agg'] = (full_df['IngroupVice'] + full_df['IngroupVirtue']) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df = pd.read_csv('experimental_data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df.drop(['HarmVirtue',\t'AuthorityVirtue',\t'PurityVirtue',\t'HarmVice',\t'PurityVice',\t'IngroupVice',\t'FairnessVirtue',\t'MoralityGeneral',\t'FairnessVice',\t'IngroupVirtue', 'AuthorityVice'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Group by 'subreddit' and calculate the mean for each moral foundation\n",
        "average_df = full_df.groupby('subreddit')[['HarmVirtue.1',\n",
        "       'AuthorityVirtue.1', 'PurityVirtue.1', 'HarmVice.1', 'PurityVice.1',\n",
        "       'IngroupVice.1', 'FairnessVirtue.1', 'MoralityGeneral.1',\n",
        "       'FairnessVice.1', 'IngroupVirtue.1', 'AuthorityVice.1']].mean().reset_index()\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(average_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df['Dominant_Moral_Foundation'] = full_df[['HarmVirtue', 'AuthorityVirtue', 'PurityVirtue', 'HarmVice', 'PurityVice', 'IngroupVice', 'FairnessVirtue', 'FairnessVice', 'IngroupVirtue', 'AuthorityVice']].idxmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "average_df['Dominant_Moral_Foundation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df['Harm_Care_Agg'] = (full_df['HarmVice.1'] + full_df['HarmVirtue.1']) / 2\n",
        "full_df['Authority_Agg'] = (full_df['AuthorityVice.1'] + full_df['HarmVirtue.1']) / 2\n",
        "full_df['Purity_Agg'] = (full_df['PurityVice.1'] + full_df['PurityVirtue.1']) / 2\n",
        "full_df['Fairness_Agg'] = (full_df['FairnessVice.1'] + full_df['FairnessVirtue.1']) / 2\n",
        "full_df['Ingroup_Agg'] = (full_df['IngroupVice.1'] + full_df['IngroupVirtue.1']) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Group by 'subreddit' and calculate the mean for each moral foundation\n",
        "average_df = full_df.groupby('subreddit')[['Harm_Care_Agg',\n",
        "       'Authority_Agg', 'Purity_Agg', 'Fairness_Agg', 'Ingroup_Agg']].mean().reset_index()\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(average_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "  subreddit      care  fairness   loyalty  authority    purity\n",
        "0   climate  0.741985  0.784272  0.716046   0.723466  0.758646"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter the DataFrame to include only comments with 'body' length greater than 20\n",
        "filtered_df = full_df[full_df['body'].str.len() > 20]\n",
        "\n",
        "# Group by 'subreddit' and calculate the mean for each moral foundation\n",
        "average_df = filtered_df.groupby('subreddit')[['care', 'fairness', 'loyalty', 'authority', 'purity']].mean().reset_index()\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(average_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_df = full_df[full_df['body'].str.len() > 1000]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
