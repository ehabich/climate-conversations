{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDM Proquest Article Compression & Download\n",
    "\n",
    "### Journal List\n",
    "- Earth System Science Data\n",
    "- Earth's Future\n",
    "- Environmental Science and Pollution Research\n",
    "- Frontiers in Marine Science\n",
    "- Global Change Biology\n",
    "- Water Resources Research\n",
    "- Biotechnology for Biofuels\n",
    "- Elementa\n",
    "- Ecological Economics\n",
    "- Food and Energy Security\n",
    "- International Journal of Energy Research\n",
    "- The Journal of Material Cycles and Waste Management\n",
    "- Mitigation and Adaptation Strategies for Global Change\n",
    "- Journal of Industrial Economics\n",
    "- Climate Policy\n",
    "- Clean Technologies and Environmental Policy\n",
    "- Wind Energy Science\n",
    "- Forests\n",
    "\n",
    "### Specifications\n",
    "**Date Range:** Jan 1st 2023 - Feb 15th 2024\\\n",
    "**Document Type:** Article\n",
    "\n",
    "Code Authors: Kathryn Link-Oberstar, Chanteria Milner, Kate Habich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs and imports\n",
    "\n",
    "%conda install xmltodict\n",
    "\n",
    "import xmltodict\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace 'dataset_name' with name of downloaded dataset\n",
    "dataset_name = 'Reduced-Env-Dataset'\n",
    "files_to_export = 'data/' + dataset_name\n",
    "parq_file_path = 'data/ES-journals.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert folder of xml to list of JSON files\n",
    "\n",
    "file_list = os.listdir(files_to_export)\n",
    "file_list = [file for file in file_list if file.endswith(\"xml\")]\n",
    "\n",
    "# TODO: may need to split up data here if > 15MB\n",
    "\n",
    "list_of_file_data = []\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(files_to_export, file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        file_as_xml = f.read()\n",
    "        file_as_dict = xmltodict.parse(file_as_xml)\n",
    "        list_of_file_data.append(json.dumps(file_as_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to parquet and compress\n",
    "\n",
    "df = pd.DataFrame(list_of_file_data)\n",
    "df.columns = [\"Data\"]\n",
    "df.to_parquet(parq_file_path, compression = 'BROTLI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate file size (must be <15MB)\n",
    "\n",
    "file_size = os.path.getsize(parq_file_path)/1000000\n",
    "print(f\"File Size: {file_size} MB\")\n",
    "if file_size <= 15:\n",
    "    print(\"File passes size requirements.\")\n",
    "else:\n",
    "    print(\"File FAILS size requirements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export and download selected journals\n",
    "\n",
    "!aws s3 cp $parq_file_path s3://pq-tdm-studio-results/tdm-ale-data/a272/results/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
